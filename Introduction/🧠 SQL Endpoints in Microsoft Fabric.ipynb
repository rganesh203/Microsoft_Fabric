{"cells":[{"cell_type":"markdown","source":["# 1. What is a SQL Endpoint in Microsoft Fabric?\n","\n","A SQL Endpoint is a read-only T-SQL interface that automatically appears when you create a Lakehouse in Microsoft Fabric.\n","It lets you run Transact-SQL queries against the structured data stored in your Lakehouse without having to write Spark code or move the data into a database.\n","\n","Think of it as:\n","    Your Lakehouse has two doors ‚Äî\n","\n","1Ô∏è‚É£ A Spark door for data engineers (PySpark, notebooks)\n","\n","2Ô∏è‚É£ A SQL door for analysts & BI tools (SQL queries, SSMS, Power BI)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"59e58124-d720-46aa-b358-1272dfbcfbcf"},{"cell_type":"markdown","source":["# 2. Where SQL Endpoints Fit in Fabric Architecture\n","\n","Microsoft Fabric has a unified data platform with multiple experiences:\n","\n","- Lakehouse ‚Üí stores raw + curated data in Delta format.\n","\n","- Data Warehouse ‚Üí SQL-based tables with transactional capabilities.\n","\n","- Notebooks / Dataflows ‚Üí data transformation.\n","\n","- Power BI ‚Üí data visualization.\n","\n","The SQL Endpoint sits between the Lakehouse and SQL-based consumers.\n","It translates Delta tables in your Lakehouse into a virtual SQL schema exposed via TDS protocol (the same as SQL Server).\n","\n","üìç Key difference from Warehouse:\n","\n","- Warehouse = stores & manages data inside a relational model (read/write).\n","\n","- SQL Endpoint = read-only query layer over Delta tables in a Lakehouse."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4edad4c3-1a07-4902-b501-f855de7996ff"},{"cell_type":"markdown","source":["# 3. How SQL Endpoints Work\n","Step-by-step:\n","\n","1. Create a Lakehouse in Microsoft Fabric.\n","\n","2. Load data into the Lakehouse ‚Äî either into the Tables folder (structured) or Files folder (raw files).\n","\n","3. When data is in the Tables folder (Delta tables), Fabric automatically generates a SQL schema.\n","\n","4. A SQL Endpoint URL is created for your Lakehouse.\n","\n","5. You can connect to this endpoint from:\n","\n","- Power BI (DirectQuery or import mode)\n","\n","- Excel (Get Data ‚Üí SQL Server)\n","\n","- SQL Server Management Studio (SSMS)\n","\n","- Azure Data Studio\n","\n","- Any JDBC/ODBC SQL client.\n","\n","6. You query the data using standard T-SQL ‚Äî no Spark knowledge required."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"682f409b-add1-4647-8acb-0a4e11b2bd58"},{"cell_type":"markdown","source":["# 4. Key Features\n","| Feature                 | Description                                                     |\n","| ----------------------- | --------------------------------------------------------------- |\n","| **Read-only access**    | No `INSERT`, `UPDATE`, `DELETE`. Only `SELECT`.                 |\n","| **T-SQL support**       | SELECT, JOIN, GROUP BY, ORDER BY, Window functions, etc.        |\n","| **Auto schema sync**    | New tables in *Tables* folder instantly appear in SQL Endpoint. |\n","| **Delta table backend** | Reads directly from Delta tables stored in OneLake.             |\n","| **Connectivity**        | TDS protocol ‚Äî compatible with SQL Server tools.                |\n","| **Security**            | Microsoft Entra ID authentication + Fabric workspace RBAC.      |\n","| **Power BI ready**      | DirectQuery supported for real-time analysis.                   |\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c8eaa7a7-b652-4730-8258-b058fe8650d1"},{"cell_type":"markdown","source":["# 5. Example Query via SQL Endpoint\n","\n","If your Lakehouse has this structure:\n","\n","Tables/\n","\n"," ‚îú‚îÄ‚îÄ Customers\n","\n"," ‚îú‚îÄ‚îÄ Sales\n"," \n"," ‚îî‚îÄ‚îÄ Products\n","\n"," You could run:\n","\n","SELECT c.CustomerName, SUM(s.Amount) AS TotalSpent\n","FROM Sales s\n","JOIN Customers c ON s.CustomerID = c.CustomerID\n","GROUP BY c.CustomerName\n","ORDER BY TotalSpent DESC;\n","\n","‚úÖ Runs directly on Delta tables\n","‚úÖ No ETL required\n","\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b3bc3296-1a53-47a5-b646-2cb7f482aecd"},{"cell_type":"markdown","source":["# 6. Connection Details\n","\n","| Parameter          | Value                                                          |\n","| ------------------ | -------------------------------------------------------------- |\n","| **Server Name**    | Provided in the \"SQL Endpoint\" tab of your Lakehouse (TDS URL) |\n","| **Authentication** | Microsoft Entra ID                                             |\n","| **Protocol**       | TDS (Tabular Data Stream)                                      |\n","| **Port**           | 1433                                                           |\n","| **Tools**          | Power BI, Excel, SSMS, Azure Data Studio, JDBC/ODBC            |\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7ae8fbe9-ed48-4d0d-bdc5-607cdded8267"},{"cell_type":"markdown","source":["# 7. Performance Considerations\n","\n","- Use optimized Delta tables (Z-Ordering, vacuuming small files) for faster reads.\n","\n","- Partition tables for large datasets to improve query pushdown.\n","\n","- Use filter predicates in SQL to avoid scanning unnecessary data.\n","\n","- Avoid Cartesian joins (performance hit).\n","\n","- Large aggregations may be slower compared to a dedicated Warehouse because it‚Äôs a virtual read layer."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1f6bbc30-cf92-457b-92e5-f95f8a4f5cae"},{"cell_type":"markdown","source":["# 8. Limitations\n","\n","- No DML: No INSERT, UPDATE, DELETE.\n","\n","- No DDL: You can‚Äôt create or drop tables via SQL Endpoint.\n","\n","- Tables only: Only data in Tables folder is exposed (Files folder is ignored).\n","\n","- No stored procedures, triggers, functions.\n","\n","- Case sensitivity: Table and column names can be case-sensitive depending on Delta configuration."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"59618f59-9e31-4d04-b4a8-fc550c755647"},{"cell_type":"markdown","source":["# 9. Security\n","\n","- Access is controlled at the Fabric workspace level.\n","\n","- Users need at least Viewer role in the workspace to query via SQL Endpoint.\n","\n","- All queries require Microsoft Entra ID sign-in ‚Äî no SQL logins.\n","\n","- Row-level or column-level security must be implemented at the Power BI or Warehouse level, not inside the SQL Endpoint."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5f6a46be-10fc-4848-8102-8efa9473c209"},{"cell_type":"markdown","source":["# 10. Common Use Cases\n","\n","1. BI Integration ‚Äî Power BI DirectQuery over Lakehouse tables.\n","\n","2. Ad-hoc SQL analysis ‚Äî Analysts can query with T-SQL instead of learning Spark.\n","\n","3. Data validation ‚Äî Compare Lakehouse data to external sources via SSMS.\n","\n","4. Prototyping dashboards ‚Äî Quickly connect Excel to Lakehouse data.\n","\n","5. Federated querying ‚Äî Join Lakehouse data with Warehouse or external SQL sources in Power BI."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ddc5d5a5-3e04-4270-a5d4-925a7e96ff16"},{"cell_type":"markdown","source":["üí° Pro Tip: If you need write capabilities or complex SQL features, you should move the data into a Fabric Data Warehouse. But for quick analysis and BI connections ‚Äî SQL Endpoint is faster and simpler."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"17c19159-2bf3-46f4-994e-2330fcc8ac96"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}