{"cells":[{"cell_type":"markdown","source":["In Microsoft Fabric, Data Factory is the next-generation evolution of Azure Data Factory — it combines the familiar capabilities of ADF with the unified, lake-centric, SaaS-first environment of Fabric.\n","\n","I’ll break this down into concepts, architecture, components, workflows, integrations, and advantages, with examples."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6bc86ebb-4a43-433f-9b92-8b0a12799e48"},{"cell_type":"markdown","source":["# 1. What is Data Factory in Microsoft Fabric?\n","\n","Microsoft Fabric’s Data Factory is essentially:\n","\n","- The data integration and orchestration layer of Fabric.\n","\n","- An evolution of Azure Data Factory (ADF), but embedded in Fabric’s SaaS environment.\n","\n","- Built to work seamlessly with OneLake, Fabric’s single, unified, multi-cloud data lake.\n","\n","Think of it as: the conveyor belt and machine operator in a factory that moves, cleans, and stages raw data so it’s ready for analytics and AI."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"57d56b10-bb5f-4daf-9868-3a8880bccca7"},{"cell_type":"markdown","source":["# 2. Why It Exists in Fabric\n","\n","Fabric aims to unify:\n","\n","- Data engineering\n","\n","- Data integration\n","\n","- Data science\n","\n","- Real-time analytics\n","\n","- Business intelligence\n","\n","While Azure Data Factory worked well for integration, it was standalone.\n","Fabric Data Factory merges that capability into a central platform, removing the need to:\n","\n","- Manage multiple services.\n","\n","- Manually connect your data pipelines to analytics tools.\n","\n","- Deal with fragmented monitoring and governance."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a5ad1db4-d824-4683-8ca8-b77c64a15e5b"},{"cell_type":"markdown","source":["# 3. Key Concepts\n","\n","| Concept                       | Fabric Data Factory Meaning                                                     |\n","| ----------------------------- | ------------------------------------------------------------------------------- |\n","| **OneLake**                   | The default destination for most pipelines — a single data lake for your org.   |\n","| **Data Pipelines**            | Orchestrations that define data movement & transformations.                     |\n","| **Dataflows Gen2**            | Fabric’s scalable data transformation engine based on Power Query.              |\n","| **Integration Runtimes (IR)** | Compute engines that execute pipeline activities (cloud-hosted or self-hosted). |\n","| **Activities**                | Tasks inside a pipeline (copy data, transform, filter, join, etc.).             |\n","| **Triggers**                  | Rules to run a pipeline (time, event, manual).                                  |\n","| **Linked Services**           | Connection configurations to data sources/destinations.                         |\n","| **Datasets**                  | References to data structures in sources or sinks.                              |\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"64432655-075a-419d-94d4-4d8a82944855"},{"cell_type":"markdown","source":["# 4. Architecture in Microsoft Fabric\n","\n","Here’s the flow:\n","\n","1. Source Systems\n","\n","    Cloud storage (Azure Blob, Amazon S3, Google Cloud Storage)\n","\n","    Databases (SQL Server, PostgreSQL, Oracle)\n","\n","    SaaS apps (Salesforce, Dynamics 365, SAP, ServiceNow)\n","\n","    On-premises data\n","\n","2. Integration Runtimes\n","\n","    Auto Integration Runtime → Default in Fabric for cloud sources\n","\n","    Self-hosted IR → Installed on-prem for firewall-protected sources\n","\n","3. Pipelines\n","\n","- Contain Activities such as:\n","\n","        Copy Data Activity\n","\n","        Dataflow Gen2 Transformation\n","\n","        Lookup\n","\n","        Filter\n","\n","        ForEach (looping)\n","\n","        Stored Procedure\n","\n","4. Transformation Layer\n","\n","    Power Query–based Dataflows Gen2\n","\n","    Can push transformations to OneLake or other sinks\n","\n","5. Destination\n","\n","    Primarily OneLake (Delta tables in Lakehouses)\n","\n","    Also supports external sinks (SQL DB, Cosmos DB, S3, etc.)\n","\n","6. Fabric Workloads Consumption\n","\n","    Data Engineering (Notebooks, Spark)\n","\n","    Data Science (ML models)\n","\n","    Real-Time Analytics (KQL DBs)\n","\n","    Power BI (Reports/Dashboards)\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1be41771-186e-438d-884c-4d846d4292ac"},{"cell_type":"markdown","source":["# 5. Components in Depth\n","### a) Data Pipelines\n","\n","    Visual drag-and-drop or JSON definition.\n","\n","    Can chain multiple activities with conditional logic.\n","\n","    Support parallelism and dependency control.\n","\n","### b) Dataflows Gen2\n","\n","    ETL logic using Power Query (same as in Excel/Power BI, but scaled).\n","\n","    Reusable transformation logic that can feed multiple datasets.\n","\n","    Can output directly into OneLake tables.\n","\n","### c) Integration Runtimes\n","\n","    Auto IR → Fully managed in Fabric; no manual provisioning.\n","\n","    Self-hosted IR → Installed in on-premises servers for firewall-protected systems.\n","\n","### d) Activities\n","\n","    Data Movement: Copy, Bulk Load\n","\n","    Data Transformation: Dataflow Gen2, Stored Procedures\n","\n","    Control Flow: If Condition, Switch, Wait, ForEach, Until\n","\n","    External Execution: Web calls, Databricks Notebooks, REST APIs\n","\n","### e) Monitoring Hub\n","\n","    Central dashboard for viewing pipeline and dataflow runs.\n","\n","    Retry failed runs directly from UI.\n","\n","    Historical logs and performance insights.\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a34bca33-65e2-40cc-a7e5-7c5d9a84d905"},{"cell_type":"markdown","source":["# 6. Integration with Other Fabric Services\n","| Fabric Service                   | Integration Role                                            |\n","| -------------------------------- | ----------------------------------------------------------- |\n","| **OneLake**                      | Native read/write for all ingested data.                    |\n","| **Lakehouse**                    | Target for structured/semi-structured data in Delta format. |\n","| **Data Engineering**             | Use Spark/Notebooks to further process ingested data.       |\n","| **Power BI**                     | Directly connect to output tables for reporting.            |\n","| **Real-Time Analytics (KQL DB)** | Push streaming or near-real-time data.                      |\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"46a48cc6-7dd1-43ca-b032-e9732485860e"},{"cell_type":"markdown","source":["# 7. Example Use Case\n","\n","Scenario: Retail company wants daily sales data from multiple stores for dashboards.\n","\n","Steps:\n","\n","1. Source: SQL Server on-prem (store sales DBs) + POS cloud API.\n","\n","2. Pipeline:\n","\n","    Copy from SQL Server → OneLake\n","\n","    Copy from API → OneLake\n","\n","3. Dataflow Gen2:\n","\n","    Merge datasets\n","\n","    Apply currency conversions\n","\n","    Filter invalid records\n","\n","4. Sink: Lakehouse in OneLake.\n","\n","5. Trigger: Run every day at 2 AM.\n","\n","6. Consumption: Power BI dashboard auto-refreshes from Lakehouse table."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e3c78e8d-774b-4693-92a6-109c7a5283d7"},{"cell_type":"markdown","source":["8. Advantages of Fabric Data Factory\n","\n","    Unified SaaS platform → No extra infra to manage.\n","\n","    Deep analytics integration → No complex linking to BI tools.\n","\n","    Familiarity for Azure Data Factory users.\n","\n","    OneLake-first architecture → Centralized, governed data store.\n","\n","    Low-code/no-code → Easy adoption by data engineers & citizen developers.\n","\n","    Security → Managed identities, RBAC, audit logs."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"78a97692-5dfa-429d-b78a-5d43c69dee05"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}