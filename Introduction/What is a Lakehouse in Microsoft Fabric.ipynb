{"cells":[{"cell_type":"markdown","source":["In Microsoft Fabric, a Lakehouse is a unified data architecture that combines the strengths of both a data lake and a data warehouse, enabling you to store, manage, and analyze large volumes of structured, semi-structured, and unstructured data in one place.\n","\n","It’s built on OneLake (Fabric’s single, enterprise-wide data lake) and uses Delta Lake tables to ensure reliability, ACID transactions, and time travel."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5aec834e-50fd-4ff5-bb0a-9b463d26b28d"},{"cell_type":"markdown","source":["# 1. What is a Lakehouse in Microsoft Fabric?\n","In Microsoft Fabric, a Lakehouse is a unified data architecture that:\n","\n","Stores all kinds of data (structured, semi-structured, and unstructured) in one place.\n","\n","Uses OneLake (Fabric’s single, organization-wide data lake) for storage.\n","\n","Stores data in Delta Lake format (Parquet + transaction log) to ensure reliability and performance.\n","\n","Lets you query with SQL, process with Spark, and visualize in Power BI — without moving the data.\n","\n","It’s basically a data lake that behaves like a data warehouse.\n","\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0beacbba-a828-47ea-ab28-33da84f82727"},{"cell_type":"markdown","source":["# 2. Why Microsoft Made the Lakehouse\n","\n","Traditionally:\n","\n","Data lakes store raw data cheaply but lack strong analytics support.\n","\n","Data warehouses are great for analytics but limited in data types and scalability.\n","\n","Companies end up maintaining both, duplicating data, and adding complexity.\n","\n","The Lakehouse solves this:\n","\n","Keep one copy of the data in OneLake.\n","\n","Make it directly usable for analytics, AI/ML, and BI."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bef0b2fe-2888-4650-aeeb-7c351cf6ba70"},{"cell_type":"markdown","source":["# 3. Core Components in a Fabric Lakehouse\n","| Component                     | Description                                                                                             |\n","| ----------------------------- | ------------------------------------------------------------------------------------------------------- |\n","| **OneLake Storage**           | The physical storage — shared across all Fabric items, so no silos.                                     |\n","| **Delta Tables**              | Tables stored in **Delta Lake format** (Parquet + \\_delta\\_log folder) with ACID properties.            |\n","| **SQL Endpoint**              | Auto-generated connection that lets you run T-SQL queries on your Lakehouse tables without extra setup. |\n","| **Apache Spark Engine**       | Lets you process big data, run transformations, train ML models, etc.                                   |\n","| **Integration with Power BI** | The SQL endpoint is automatically linked to Power BI datasets for reporting.                            |\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3472e4e1-1746-44e7-a344-0e29ee07578b"},{"cell_type":"markdown","source":["# 4. Data Flow in a Fabric Lakehouse\n","Step-by-step process:\n","\n","Ingest Data\n","\n","Use Data pipelines (Fabric’s ETL/ELT tool), Dataflows Gen2, or direct file upload.\n","\n","Supported formats: CSV, JSON, Parquet, Avro, Delta, images, videos, etc.\n","\n","Store in OneLake\n","\n","All files are stored in Delta or native format inside OneLake.\n","\n","Structured data is stored as Delta tables.\n","\n","Transform Data\n","\n","Use Apache Spark Notebooks for big data transformations.\n","\n","Use Pipelines or Dataflows Gen2 for low/no-code transformations.\n","\n","Query\n","\n","SQL endpoint → For analysts who prefer SQL.\n","\n","Spark → For data engineers/scientists who need advanced processing.\n","\n","Consume\n","\n","Power BI can directly connect to the SQL endpoint.\n","\n","External tools can connect via ODBC/JDBC using the Delta tables."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"81938f4b-172a-4a20-b56b-ca5a8886a50f"},{"cell_type":"markdown","source":["# 5. Key Benefits\n","✅ Single Source of Truth – One copy of the data, no ETL duplication.\n","\n","✅ Multi-Engine Access – Same data accessible from SQL, Spark, Power BI, and even Real-Time Analytics.\n","\n","✅ Open Format – Delta Lake (Parquet) ensures interoperability.\n","\n","✅ Performance – Query optimization, indexing, caching.\n","\n","✅ Governance – Works with Microsoft Purview for data discovery, lineage, and security.\n","\n","✅ Time Travel – Query data as it existed in the past (Delta feature)."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"48a65abd-3126-4e44-9b72-66a29be0f1cd"},{"cell_type":"markdown","source":["# 6. Lakehouse vs Data Warehouse in Fabric\n","\n","| Feature    | Lakehouse                                       | Data Warehouse                   |\n","| ---------- | ----------------------------------------------- | -------------------------------- |\n","| Storage    | OneLake (Delta/Parquet)                         | Proprietary optimized storage    |\n","| Data Types | Any type (structured, semi/unstructured)        | Structured only                  |\n","| Processing | Spark + SQL                                     | SQL only                         |\n","| Best For   | Mixed workloads (BI + AI/ML)                    | BI and reporting                 |\n","| Cost       | Cheaper for storage, pay-per-use for processing | Pay for reserved compute/storage |\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9044c25e-ec85-4cb7-8bfa-f013bd600f60"},{"cell_type":"markdown","source":["# 7. Example Use Cases\n","\n","Retail – Combine sales transactions (structured) with customer clickstream logs (semi-structured) and product images (unstructured) for analytics + ML.\n","\n","IoT – Store raw sensor data, clean it with Spark, then report trends in Power BI.\n","\n","Financial Services – Process large volumes of transaction data, run fraud detection models, and generate dashboards — all from the same store.\n","\n","Healthcare – Keep patient records, lab results, and imaging data together for analytics and AI."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a2c1346b-445d-4588-b39c-7c7237020f5b"},{"cell_type":"markdown","source":["# 8. Architecture Diagram (Conceptual)\n","\n","           ┌─────────────────────────────┐\n","           │         Data Sources         │\n","           │ Files, APIs, Databases, IoT  │\n","           └─────────────┬───────────────┘\n","                         │\n","                ┌────────▼────────┐\n","                │   Ingestion      │\n","                │ Pipelines,       │\n","                │ Dataflows Gen2   │\n","                └────────┬────────┘\n","                         │\n","         ┌───────────────▼────────────────┐\n","         │          OneLake                │\n","         │   (Delta Tables + Files)        │\n","         └───────────┬────────────────────┘\n","                     │\n","                     \n","      ┌──────────────┼───────────────┐\n","      │              │               │\n","      \n","┌─────▼─────┐  ┌─────▼─────┐   ┌─────▼──────┐\n","\n","│ SQL Endpt │  │  Spark     │   │ Real-time\n","\n"," │\n","│ (T-SQL)   │  │ (Py/Scala)│   │ Analytics  │\n","\n","└─────┬─────┘  └─────┬─────┘   └─────┬──────┘\n","      \n","      │              │               │\n","      \n","      └───────┬──────┴───────────────┘\n","              │\n","\n","       ┌──────▼──────┐\n","       │  Power BI   │\n","       │ Reports/Dash│\n","       └─────────────┘\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1f528c35-8e37-4fe0-8d13-6cadc9a72ab0"},{"cell_type":"markdown","source":["If you like, I can make you a full-color Fabric Lakehouse diagram showing OneLake, ingestion, SQL endpoints, and Power BI integration so it’s visually clear.\n","That will make it easier to explain in presentations or documentation."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"34face14-22bd-45d4-84e0-9ee1aaf602d5"},{"cell_type":"markdown","source":[],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"57f7c3e3-0bdf-4c76-9fb9-63c911b0f2e4"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}