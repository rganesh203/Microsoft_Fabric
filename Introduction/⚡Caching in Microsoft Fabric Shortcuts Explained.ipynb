{"cells":[{"cell_type":"markdown","source":["Caching in Microsoft Fabric Shortcuts clearly and in detail, because this is one of those topics where the small nuances can make a big performance difference."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a29f7814-bc30-40da-b4c8-092d664f6132"},{"cell_type":"markdown","source":["# 1. Refresher: What Are Fabric Shortcuts?\n","\n","In Microsoft Fabric, a shortcut is essentially:\n","\n","- A symbolic link (pointer) to a dataset stored in another storage location.\n","\n","- The storage could be:\n","\n","    - OneLake (another workspace or region)\n","\n","    - External storage (Azure Data Lake Storage Gen2, Amazon S3, etc.)\n","\n","- No physical copy is made at creation â†’ You only store a reference, so storage cost is near zero.\n","\n","Shortcut Path: /Tables/Sales\n","Points to: adls://external-container@westus/data/Sales/\n","\n","If your Fabric compute is in East US, every read from that shortcut goes over the network to West US â€” unless you cache it.\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5bd0da44-79c0-4d65-868f-1db8fdc47d4e"},{"cell_type":"markdown","source":["# 2. Why Caching Exists\n","\n","Without caching:\n","\n","- Latency: Each read may cross regions or external networks.\n","\n","- Throughput Bottlenecks: Dependent on source storage bandwidth.\n","\n","- Variable Performance: Network congestion can cause query times to fluctuate.\n","\n","- Cost Impact: External storage reads can cause egress charges.\n","\n","With caching:\n","\n","- Data is stored locally inside OneLake near your compute region.\n","\n","- Subsequent reads avoid remote calls, making them faster and more predic"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"39dc2fe5-f2af-462f-9746-f25ab8d8df44"},{"cell_type":"markdown","source":["# 3. How Caching Works Internally\n","\n","Think of it as a read-through cache in front of your shortcut data.\n","\n","Step-by-step:\n","\n","1. User/query requests data from a shortcut.\n","\n","2. Fabric checks cache in OneLake for the requested file/partition.\n","\n","3. If cache miss:\n","\n","- Reads file from source storage.\n","\n","- Stores a copy in the OneLake cache zone.\n","\n","4. If cache hit:\n","\n","- Reads file directly from OneLake cache.\n","\n","5.Cache is partition-aware â€” only the accessed chunks (files, parquet partitions) are cached, not necessarily the entire dataset."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c40c207d-658c-4bdb-a35c-8e8b9650cbae"},{"cell_type":"markdown","source":["# 4. Caching Modes\n","| Mode                  | Mechanism                                                | Pros                                                     | Cons                                      | Best For                                       |\n","| --------------------- | -------------------------------------------------------- | -------------------------------------------------------- | ----------------------------------------- | ---------------------------------------------- |\n","| **On-demand caching** | Loads only accessed files into cache when first queried. | Lower initial storage cost; automatic.                   | First access is slow; cache is partial.   | Exploratory analysis, sporadic access.         |\n","| **Full caching**      | Pre-loads the entire dataset into OneLake cache.         | Subsequent queries are all fast; consistent performance. | Higher initial load time & storage usage. | Production workloads with frequent full scans. |\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e001cba5-528c-473c-bf7f-2af73de9c7fb"},{"cell_type":"markdown","source":["# 5. Cache Storage Location & Lifecycle\n","\n","- Stored in OneLake-managed cache in the same region as your Fabric workspace.\n","\n","- Ephemeral: Cache is maintained until space is needed for newer cached data.\n","\n","- Not auto-synced: If the source file changes, the cache will still serve the old version until:\n","\n","    - Cache is manually refreshed, or\n","\n","    - Time-to-live (TTL) expires (configurable for some workloads)."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"466c0b9c-8c62-4949-8fe8-4e7f6ef04b2a"},{"cell_type":"markdown","source":["# 6. Cache Refreshing\n","\n","You have three options to update cached data:\n","\n","1. Manual refresh â€” Triggered via Fabric UI or API.\n","\n","2. Scheduled refresh â€” Useful for known update patterns (e.g., daily ETL runs).\n","\n","3. Query-triggered refresh â€” Rare, but possible if a query explicitly requests latest data.\n","\n","ğŸ’¡ Best practice: For high-importance data, align cache refresh with your data pipeline schedule."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9443fc1d-ff75-412d-9a0f-120696da637f"},{"cell_type":"markdown","source":["# 7. Performance Impact\n","\n","- Cold query (first time, no cache): Might take seconds to minutes depending on size, distance, and source throughput.\n","\n","- Warm query (cache hit): Often 5â€“20Ã— faster; measured in milliseconds for small-to-medium datasets.\n","\n","- Throughput gain: Local OneLake reads can handle high concurrency without bottlenecking the source.\n","\n","Example:\n","Dataset: 1 TB Parquet in ADLS (West US)\n","Fabric workspace: East US\n","\n","- Without caching: Query scan â†’ ~120 MB/s throughput (network-bound).\n","\n","- With caching: Query scan â†’ ~800+ MB/s throughput (disk-bound, local)."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ce8fa3a2-3a77-4707-96e9-1be906f136df"},{"cell_type":"markdown","source":["# 8. Cost Considerations\n","\n","- Storage cost: Cached data consumes OneLake capacity.\n","\n","- Data egress: First read from external region or cloud provider incurs egress charges (Azure/AWS rules apply).\n","\n","- Compute cost: Queries on cached data may reduce compute runtimes, lowering Fabric capacity consumption."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6429e21a-8f11-4323-abf3-11a9673fcd0d"},{"cell_type":"markdown","source":["# 9. Limitations\n","\n","- Data freshness: Cache doesnâ€™t auto-update instantly.\n","\n","- Partial caching: On-demand caching wonâ€™t help if your query scans new files every time.\n","\n","- No infinite retention: Cache eviction happens when space is full."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"587d3338-3ba7-446a-862c-eaeb1ec951ee"},{"cell_type":"markdown","source":["# 10. Best Practices for Using Caching\n","\n","1. Enable full caching for datasets with:\n","\n","- Heavy repeated queries\n","\n","- Known refresh windows\n","\n","- Predictable data changes\n","\n","2. Stick with on-demand caching for:\n","\n","- Ad-hoc analytics\n","\n","- Very large datasets where only subsets are needed\n","\n","3. Monitor cache hit ratio to justify storage usage.\n","\n","4. Locate storage in same region where possible â€” caching helps, but local is still fastest.\n","\n","5. Automate cache refresh after data ingestion to avoid stale results."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"651ff2bd-326e-46fd-a91c-0c2b776ca4e7"},{"cell_type":"markdown","source":["# 11. Visual Diagram â€“ Caching Flow\n","\n","Hereâ€™s how the data flow looks:"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"13cca6f1-afa8-4e54-aa1b-a5b08427e9dd"},{"cell_type":"markdown","source":["             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n","             â”‚  Shortcut Reference  â”‚\n","             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","                       â”‚\n","        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n","        â”‚    Check OneLake Local Cache   â”‚\n","        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","                â”‚ Cache Hit    â”‚ Cache Miss\n","         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”       â”‚\n","         â”‚ Return Data â”‚       â”‚\n","         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â–¼\n","                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n","                          â”‚ Source Storageâ”‚\n","                          â”‚  (ADLS/S3)    â”‚\n","                          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n","                                  â–¼\n","                        Store in OneLake Cache\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e03f26eb-c0cd-4f7b-9894-32ebe0ec1f05"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}